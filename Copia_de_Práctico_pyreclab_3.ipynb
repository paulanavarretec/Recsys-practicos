{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copia_de_Práctico_pyreclab_3.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/paulanavarretec/Recsys-practicos/blob/master/Copia_de_Pra%CC%81ctico_pyreclab_3.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "Ug0ZdoCQ8v_-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Ayudantía 3 - Sistemas Recomendadores: Pyreclab"
      ]
    },
    {
      "metadata": {
        "id": "8VO7sT3xSI9G",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "** *texto en cursiva*Nombre(s):** Paula Navarrete - Astrid San Martín"
      ]
    },
    {
      "metadata": {
        "id": "QYb_yqvJ9Azs",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Setup"
      ]
    },
    {
      "metadata": {
        "id": "uDf4Fq2sVXoe",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Paso 1:** Descarga de archivos:\n",
        "\n",
        "*   `dictionary.p`\n",
        "*   `dictionary-stemm.p`\n",
        "*  `tfidf_model.p`\n",
        "*  `tfidf_model-stemm.p`"
      ]
    },
    {
      "metadata": {
        "id": "nAU2KqtbO-H0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 216
        },
        "outputId": "ae9f253f-638e-4bc9-e404-3ba4f4e63fe4"
      },
      "cell_type": "code",
      "source": [
        "# Descargue los archivos ejecutando este comando\n",
        "!curl -L -o 'resources.tar.gz' \"https://drive.google.com/uc?export=download&id=1_Vp-veFfqCFkaEs-qVx99DYrAexBfq8w\"\n",
        "\n",
        "# Descomprima el archivo\n",
        "!tar -xvf resources.tar.gz"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\r\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100   388    0   388    0     0    388      0 --:--:--  0:00:01 --:--:--   318\n",
            "100 1754k  100 1754k    0     0  1754k      0  0:00:01  0:00:01 --:--:-- 35.7M\n",
            "resources/\n",
            "resources/dictionary-stemm.p\n",
            "resources/dictionary.p\n",
            "resources/tfidf_model-stemm.p\n",
            "resources/tfidf_model.p\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "LdcX_Hv8VtMC",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Paso 1.5:** Descarga del dataset:"
      ]
    },
    {
      "metadata": {
        "id": "Oe-uwhdrQflY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 150
        },
        "outputId": "818812a7-99e8-4908-9329-6838be48a983"
      },
      "cell_type": "code",
      "source": [
        "# Puede descargar el dataset ejecutando el siguiente comando\n",
        "!curl -L -o 'dataset.tar.gz' \"https://drive.google.com/uc?export=download&id=1by4BZRPeUSnQRbwJWc-OKpIF6YBpCa7s\"\n",
        "\n",
        "# Y descomprimirlo con\n",
        "!tar -xvf dataset.tar.gz"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\r\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100   388    0   388    0     0    129      0 --:--:--  0:00:03 --:--:--   127\n",
            "100 3117k    0 3117k    0     0  1039k      0 --:--:--  0:00:03 --:--:-- 1039k\n",
            "./._corpus1.csv\n",
            "corpus1.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "C38vKnWX9CFM",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Paso 2:** Para este práctico es necesario instalar las siguentes dependencias:"
      ]
    },
    {
      "metadata": {
        "id": "qrQao0AE9ZgV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1019
        },
        "outputId": "361dd68a-30c1-4d3c-cf66-c421d63c3632"
      },
      "cell_type": "code",
      "source": [
        "!pip install nltk\n",
        "!pip install sklearn\n",
        "!pip install gensim\n",
        "!pip install pandas\n",
        "!pip install numpy"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.6/dist-packages (3.2.5)\r\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from nltk) (1.11.0)\n",
            "Collecting sklearn\n",
            "  Downloading https://files.pythonhosted.org/packages/1e/7a/dbb3be0ce9bd5c8b7e3d87328e79063f8b263b2b1bfa4774cb1147bfcd3f/sklearn-0.0.tar.gz\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from sklearn) (0.19.2)\n",
            "Building wheels for collected packages: sklearn\n",
            "  Running setup.py bdist_wheel for sklearn ... \u001b[?25l-\b \bdone\n",
            "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/76/03/bb/589d421d27431bcd2c6da284d5f2286c8e3b2ea3cf1594c074\n",
            "Successfully built sklearn\n",
            "Installing collected packages: sklearn\n",
            "Successfully installed sklearn-0.0\n",
            "Collecting gensim\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/86/f3/37504f07651330ddfdefa631ca5246974a60d0908216539efda842fd080f/gensim-3.5.0-cp36-cp36m-manylinux1_x86_64.whl (23.5MB)\n",
            "\u001b[K    100% |████████████████████████████████| 23.5MB 1.6MB/s \n",
            "\u001b[?25hCollecting smart-open>=1.2.1 (from gensim)\n",
            "  Downloading https://files.pythonhosted.org/packages/cf/3d/5f3a9a296d0ba8e00e263a8dee76762076b9eb5ddc254ccaa834651c8d65/smart_open-1.6.0.tar.gz\n",
            "Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.6/dist-packages (from gensim) (0.19.1)\n",
            "Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.14.5)\n",
            "Requirement already satisfied: six>=1.5.0 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.11.0)\n",
            "Collecting boto>=2.32 (from smart-open>=1.2.1->gensim)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/23/10/c0b78c27298029e4454a472a1919bde20cb182dab1662cec7f2ca1dcc523/boto-2.49.0-py2.py3-none-any.whl (1.4MB)\n",
            "\u001b[K    100% |████████████████████████████████| 1.4MB 12.9MB/s \n",
            "\u001b[?25hCollecting bz2file (from smart-open>=1.2.1->gensim)\n",
            "  Downloading https://files.pythonhosted.org/packages/61/39/122222b5e85cd41c391b68a99ee296584b2a2d1d233e7ee32b4532384f2d/bz2file-0.98.tar.gz\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.2.1->gensim) (2.18.4)\n",
            "Collecting boto3 (from smart-open>=1.2.1->gensim)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ff/18/ca92503c20875e9696962e899f6c1c7324b07f045cded385e0f8e8955fca/boto3-1.8.5-py2.py3-none-any.whl (128kB)\n",
            "\u001b[K    100% |████████████████████████████████| 133kB 24.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim) (2018.8.24)\n",
            "Requirement already satisfied: idna<2.7,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim) (2.6)\n",
            "Requirement already satisfied: urllib3<1.23,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim) (1.22)\n",
            "Collecting jmespath<1.0.0,>=0.7.1 (from boto3->smart-open>=1.2.1->gensim)\n",
            "  Downloading https://files.pythonhosted.org/packages/b7/31/05c8d001f7f87f0f07289a5fc0fc3832e9a57f2dbd4d3b0fee70e0d51365/jmespath-0.9.3-py2.py3-none-any.whl\n",
            "Collecting botocore<1.12.0,>=1.11.5 (from boto3->smart-open>=1.2.1->gensim)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9e/ef/5d6d9995946379e018bca8353271a3d7068daf5892f4bcdddd59faded358/botocore-1.11.5-py2.py3-none-any.whl (4.6MB)\n",
            "\u001b[K    100% |████████████████████████████████| 4.6MB 5.6MB/s \n",
            "\u001b[?25hCollecting s3transfer<0.2.0,>=0.1.10 (from boto3->smart-open>=1.2.1->gensim)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d7/14/2a0004d487464d120c9fb85313a75cd3d71a7506955be458eebfe19a6b1d/s3transfer-0.1.13-py2.py3-none-any.whl (59kB)\n",
            "\u001b[K    100% |████████████████████████████████| 61kB 20.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: python-dateutil<3.0.0,>=2.1; python_version >= \"2.7\" in /usr/local/lib/python3.6/dist-packages (from botocore<1.12.0,>=1.11.5->boto3->smart-open>=1.2.1->gensim) (2.5.3)\n",
            "Collecting docutils>=0.10 (from botocore<1.12.0,>=1.11.5->boto3->smart-open>=1.2.1->gensim)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/36/fa/08e9e6e0e3cbd1d362c3bbee8d01d0aedb2155c4ac112b19ef3cae8eed8d/docutils-0.14-py3-none-any.whl (543kB)\n",
            "\u001b[K    100% |████████████████████████████████| 552kB 17.7MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: smart-open, bz2file\n",
            "  Running setup.py bdist_wheel for smart-open ... \u001b[?25l-\b \bdone\n",
            "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/73/f1/9b/ccf93d4ba073b6f79b1ed9df68ab5ce048d8136d0efcf90b30\n",
            "  Running setup.py bdist_wheel for bz2file ... \u001b[?25l-\b \bdone\n",
            "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/81/75/d6/e1317bf09bf1af5a30befc2a007869fa6e1f516b8f7c591cb9\n",
            "Successfully built smart-open bz2file\n",
            "Installing collected packages: boto, bz2file, jmespath, docutils, botocore, s3transfer, boto3, smart-open, gensim\n",
            "Successfully installed boto-2.49.0 boto3-1.8.5 botocore-1.11.5 bz2file-0.98 docutils-0.14 gensim-3.5.0 jmespath-0.9.3 s3transfer-0.1.13 smart-open-1.6.0\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (0.22.0)\n",
            "Requirement already satisfied: pytz>=2011k in /usr/local/lib/python3.6/dist-packages (from pandas) (2018.5)\n",
            "Requirement already satisfied: python-dateutil>=2 in /usr/local/lib/python3.6/dist-packages (from pandas) (2.5.3)\n",
            "Requirement already satisfied: numpy>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from pandas) (1.14.5)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2->pandas) (1.11.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (1.14.5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "gj38t3yY9dMW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "import nltk\n",
        "import sklearn\n",
        "import gensim\n",
        "import string\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from scipy.sparse import csr_matrix\n",
        "from collections import Counter\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem.porter import PorterStemmer \n",
        "from gensim import corpora, models, similarities\n",
        "from sklearn.neighbors import NearestNeighbors"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PUYnjZ1yOY-A",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Preprocesamiento de datos"
      ]
    },
    {
      "metadata": {
        "id": "me-LXrP2Ocjc",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Lo primero es descargar las librerías de NLTK necesarias:"
      ]
    },
    {
      "metadata": {
        "id": "1Ru8N7mZ9exU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 83
        },
        "outputId": "91c4c70e-6b9c-4125-b907-903a40887cdc"
      },
      "cell_type": "code",
      "source": [
        "# Download corpora\n",
        "nltk.download('punkt')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "metadata": {
        "id": "zUzN9tQTQf2k",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Para comenzar cargaremos el set de datos en un *dataframe* de Pandas, e imprimimos los 5 primeros registros para visualizar la estructura de los datos."
      ]
    },
    {
      "metadata": {
        "id": "yk2PJqkW92Ha",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 259
        },
        "outputId": "2efef974-4fc8-4cb4-93f5-02be173a3f82"
      },
      "cell_type": "code",
      "source": [
        "corpus_df = pd.read_csv('./corpus1.csv', sep='\\t', header=None, encoding='latin')\n",
        "corpus_df.columns = ['id', 'title', 'abstract']\n",
        "corpus_df = corpus_df[['id', 'title', 'abstract']]\n",
        "corpus_df[:5]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>title</th>\n",
              "      <th>abstract</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>100002</td>\n",
              "      <td>Nonlinear Shape Statistics in Mumford{Shah Bas...</td>\n",
              "      <td>We present a variational integration of nonlin...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>100007</td>\n",
              "      <td>On the Complexity of Equilibria</td>\n",
              "      <td>We prove complexity, approximability, and inap...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>100008</td>\n",
              "      <td>On QoS-Aware Publish-Subscribe</td>\n",
              "      <td>This position paper addresses the issue of sup...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>10001</td>\n",
              "      <td>Checking Mergeable Priority Queues</td>\n",
              "      <td>We present an efficient algorithm which can ch...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>100012</td>\n",
              "      <td>Mobile Code Security by Java Bytecode Instrume...</td>\n",
              "      <td>Mobile code provides significant opportunities...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       id                                              title  \\\n",
              "0  100002  Nonlinear Shape Statistics in Mumford{Shah Bas...   \n",
              "1  100007                    On the Complexity of Equilibria   \n",
              "2  100008                     On QoS-Aware Publish-Subscribe   \n",
              "3   10001                 Checking Mergeable Priority Queues   \n",
              "4  100012  Mobile Code Security by Java Bytecode Instrume...   \n",
              "\n",
              "                                            abstract  \n",
              "0  We present a variational integration of nonlin...  \n",
              "1  We prove complexity, approximability, and inap...  \n",
              "2  This position paper addresses the issue of sup...  \n",
              "3  We present an efficient algorithm which can ch...  \n",
              "4  Mobile code provides significant opportunities...  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "metadata": {
        "id": "2c2NWVPnQmFU",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Lo siguiente es implementar una función que transforme texto no estructurado a una lista de tokens procesados."
      ]
    },
    {
      "metadata": {
        "id": "PerFw5VF-kjf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 39
        },
        "outputId": "2efdbc64-623c-42cb-8ff7-b58e38e5982c"
      },
      "cell_type": "code",
      "source": [
        "stemm = False\n",
        "stemmer = PorterStemmer()\n",
        "\n",
        "def get_tokens(text):\n",
        "    lowers = text.lower()\n",
        "    no_punctuation = lowers.translate({ord(c): None for c in string.punctuation})\n",
        "    tokens = nltk.word_tokenize(no_punctuation)\n",
        "    if stemm:\n",
        "        tokens = map(stemmer.stem, tokens)\n",
        "        \n",
        "    return tokens\n",
        "\n",
        "get_tokens(\"I'm a super student for recommender systems!\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['im', 'a', 'super', 'student', 'for', 'recommender', 'systems']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "metadata": {
        "id": "3csGVr5GQwnR",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Pregunta:** Explique en sus palabras qué hace la función `get_tokens()`.\n",
        "\n",
        "**Respuesta:**procesa el texto llevando todas las letras a minúsculas, sacando los signos de puntuación, y se crea un arreglo separando por palabras. No se retiran las \"stop words\". \n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "5BuNyD3zRUrP",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Ahora se tiene que generar un diccionario con todas las palabras del *corpus*.\n",
        "\n",
        "Se recomienda revisar la documentación de gensim y leer cómo usar los diccionarios: [corpora.dictionary](https://radimrehurek.com/gensim/corpora/dictionary.html)"
      ]
    },
    {
      "metadata": {
        "id": "HRY9VYwk__HP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 259
        },
        "outputId": "202805ba-b2ff-4f57-8135-54d7c4657bac"
      },
      "cell_type": "code",
      "source": [
        "dict_file = './resources/dictionary-stemm.p' if stemm else './resources/dictionary.p'\n",
        "if os.path.isfile(dict_file):\n",
        "    dictionary = corpora.dictionary.Dictionary().load(dict_file)\n",
        "else:\n",
        "    dictionary = corpora.dictionary.Dictionary(documents=corpus_df.tokenised_abstract.tolist())\n",
        "    dictionary.save(dict_file)\n",
        "    \n",
        "corpus_df['tokenized_abstract'] = corpus_df.abstract.map(get_tokens)\n",
        "corpus_df[:5]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>title</th>\n",
              "      <th>abstract</th>\n",
              "      <th>tokenized_abstract</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>100002</td>\n",
              "      <td>Nonlinear Shape Statistics in Mumford{Shah Bas...</td>\n",
              "      <td>We present a variational integration of nonlin...</td>\n",
              "      <td>[we, present, a, variational, integration, of,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>100007</td>\n",
              "      <td>On the Complexity of Equilibria</td>\n",
              "      <td>We prove complexity, approximability, and inap...</td>\n",
              "      <td>[we, prove, complexity, approximability, and, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>100008</td>\n",
              "      <td>On QoS-Aware Publish-Subscribe</td>\n",
              "      <td>This position paper addresses the issue of sup...</td>\n",
              "      <td>[this, position, paper, addresses, the, issue,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>10001</td>\n",
              "      <td>Checking Mergeable Priority Queues</td>\n",
              "      <td>We present an efficient algorithm which can ch...</td>\n",
              "      <td>[we, present, an, efficient, algorithm, which,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>100012</td>\n",
              "      <td>Mobile Code Security by Java Bytecode Instrume...</td>\n",
              "      <td>Mobile code provides significant opportunities...</td>\n",
              "      <td>[mobile, code, provides, significant, opportun...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       id                                              title  \\\n",
              "0  100002  Nonlinear Shape Statistics in Mumford{Shah Bas...   \n",
              "1  100007                    On the Complexity of Equilibria   \n",
              "2  100008                     On QoS-Aware Publish-Subscribe   \n",
              "3   10001                 Checking Mergeable Priority Queues   \n",
              "4  100012  Mobile Code Security by Java Bytecode Instrume...   \n",
              "\n",
              "                                            abstract  \\\n",
              "0  We present a variational integration of nonlin...   \n",
              "1  We prove complexity, approximability, and inap...   \n",
              "2  This position paper addresses the issue of sup...   \n",
              "3  We present an efficient algorithm which can ch...   \n",
              "4  Mobile code provides significant opportunities...   \n",
              "\n",
              "                                  tokenized_abstract  \n",
              "0  [we, present, a, variational, integration, of,...  \n",
              "1  [we, prove, complexity, approximability, and, ...  \n",
              "2  [this, position, paper, addresses, the, issue,...  \n",
              "3  [we, present, an, efficient, algorithm, which,...  \n",
              "4  [mobile, code, provides, significant, opportun...  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "metadata": {
        "id": "xPrsuu7jX5KK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 39
        },
        "outputId": "5a75edc2-b1c6-427e-d5af-5cb5bf36a830"
      },
      "cell_type": "code",
      "source": [
        "print(corpus_df['tokenized_abstract'][0][0],corpus_df['tokenized_abstract'][0][42])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "we pca\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "BB7mwxklRxs_",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Pregunta:** Explique a qué corresponde la columna `tokenised_abstract` del dataframe.\n",
        "\n",
        "**Respuesta:**La columna contiene el vector con las palabras después de pasar el abstract por la función *get_tokens*, es decir todas las letras en minúscula, sin puntación, palabras separadas de cada texto contenido en la columna abstract.\n"
      ]
    },
    {
      "metadata": {
        "id": "M6QriWJKAMZn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 259
        },
        "outputId": "da8b8a5e-10ec-4d48-e527-020a5ce9701c"
      },
      "cell_type": "code",
      "source": [
        "corpus_df['bow'] = corpus_df.tokenized_abstract.map(dictionary.doc2bow)\n",
        "del corpus_df['tokenized_abstract']\n",
        "corpus = corpus_df['bow'].tolist()\n",
        "corpus_df[:5]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>title</th>\n",
              "      <th>abstract</th>\n",
              "      <th>bow</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>100002</td>\n",
              "      <td>Nonlinear Shape Statistics in Mumford{Shah Bas...</td>\n",
              "      <td>We present a variational integration of nonlin...</td>\n",
              "      <td>[(0, 1), (1, 1), (3, 1), (4, 1), (5, 1), (6, 1...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>100007</td>\n",
              "      <td>On the Complexity of Equilibria</td>\n",
              "      <td>We prove complexity, approximability, and inap...</td>\n",
              "      <td>[(4, 5), (7, 2), (8, 1), (10, 1), (30, 3), (35...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>100008</td>\n",
              "      <td>On QoS-Aware Publish-Subscribe</td>\n",
              "      <td>This position paper addresses the issue of sup...</td>\n",
              "      <td>[(1, 1), (4, 6), (7, 1), (16, 1), (22, 1), (27...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>10001</td>\n",
              "      <td>Checking Mergeable Priority Queues</td>\n",
              "      <td>We present an efficient algorithm which can ch...</td>\n",
              "      <td>[(4, 7), (7, 2), (8, 1), (10, 1), (16, 1), (17...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>100012</td>\n",
              "      <td>Mobile Code Security by Java Bytecode Instrume...</td>\n",
              "      <td>Mobile code provides significant opportunities...</td>\n",
              "      <td>[(4, 4), (5, 1), (7, 1), (10, 2), (16, 5), (22...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       id                                              title  \\\n",
              "0  100002  Nonlinear Shape Statistics in Mumford{Shah Bas...   \n",
              "1  100007                    On the Complexity of Equilibria   \n",
              "2  100008                     On QoS-Aware Publish-Subscribe   \n",
              "3   10001                 Checking Mergeable Priority Queues   \n",
              "4  100012  Mobile Code Security by Java Bytecode Instrume...   \n",
              "\n",
              "                                            abstract  \\\n",
              "0  We present a variational integration of nonlin...   \n",
              "1  We prove complexity, approximability, and inap...   \n",
              "2  This position paper addresses the issue of sup...   \n",
              "3  We present an efficient algorithm which can ch...   \n",
              "4  Mobile code provides significant opportunities...   \n",
              "\n",
              "                                                 bow  \n",
              "0  [(0, 1), (1, 1), (3, 1), (4, 1), (5, 1), (6, 1...  \n",
              "1  [(4, 5), (7, 2), (8, 1), (10, 1), (30, 3), (35...  \n",
              "2  [(1, 1), (4, 6), (7, 1), (16, 1), (22, 1), (27...  \n",
              "3  [(4, 7), (7, 2), (8, 1), (10, 1), (16, 1), (17...  \n",
              "4  [(4, 4), (5, 1), (7, 1), (10, 2), (16, 5), (22...  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "metadata": {
        "id": "BtaBE7snSDMe",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Pregunta:** Explique a qué corresponde la columna `bow`\n",
        "\n",
        "**Respuesta:**Bag of Words (BOW) está representando el texto una vez pasado por la función *get_tokens*, en un vector de acuerdo al vocabulario. No interesa el orden de las palabras sólo la ocurrencia de la palabra. Es una forma de representar el texto para poder usarlo en un modelo. Se queda con las palabras presentes en el diccionario.\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "f23GriULTHgV",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Tf-idf"
      ]
    },
    {
      "metadata": {
        "id": "C7ju5n3xTKtj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "outputId": "18c27267-e43e-4eff-b1cb-bc82be4fa5ac"
      },
      "cell_type": "code",
      "source": [
        "tfidf_model_file = 'resources/tfidf_model-stemm.p' if stemm else 'resources/tfidf_model.p'\n",
        "if os.path.isfile(tfidf_model_file):\n",
        "    tfidf_model = models.tfidfmodel.TfidfModel().load(tfidf_model_file)\n",
        "else:\n",
        "    tfidf_model = models.tfidfmodel.TfidfModel(corpus, dictionary=dictionary)\n",
        "    tfidf_model.save(tfidf_model_file)\n",
        "\n",
        "corpus_df['tf_idf'] = tfidf_model[corpus_df.bow.tolist()]\n",
        "corpus_df[:5]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>title</th>\n",
              "      <th>abstract</th>\n",
              "      <th>bow</th>\n",
              "      <th>tf_idf</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>100002</td>\n",
              "      <td>Nonlinear Shape Statistics in Mumford{Shah Bas...</td>\n",
              "      <td>We present a variational integration of nonlin...</td>\n",
              "      <td>[(0, 1), (1, 1), (3, 1), (4, 1), (5, 1), (6, 1...</td>\n",
              "      <td>[(0, 0.19689725999527163), (1, 0.0861613877917...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>100007</td>\n",
              "      <td>On the Complexity of Equilibria</td>\n",
              "      <td>We prove complexity, approximability, and inap...</td>\n",
              "      <td>[(4, 5), (7, 2), (8, 1), (10, 1), (30, 3), (35...</td>\n",
              "      <td>[(4, 0.0033554011043417254), (7, 0.02333778550...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>100008</td>\n",
              "      <td>On QoS-Aware Publish-Subscribe</td>\n",
              "      <td>This position paper addresses the issue of sup...</td>\n",
              "      <td>[(1, 1), (4, 6), (7, 1), (16, 1), (22, 1), (27...</td>\n",
              "      <td>[(1, 0.06276351152911328), (4, 0.0049492930133...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>10001</td>\n",
              "      <td>Checking Mergeable Priority Queues</td>\n",
              "      <td>We present an efficient algorithm which can ch...</td>\n",
              "      <td>[(4, 7), (7, 2), (8, 1), (10, 1), (16, 1), (17...</td>\n",
              "      <td>[(4, 0.0022699486545179476), (7, 0.01127724975...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>100012</td>\n",
              "      <td>Mobile Code Security by Java Bytecode Instrume...</td>\n",
              "      <td>Mobile code provides significant opportunities...</td>\n",
              "      <td>[(4, 4), (5, 1), (7, 1), (10, 2), (16, 5), (22...</td>\n",
              "      <td>[(4, 0.001715799318906219), (5, 0.031751265629...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       id                                              title  \\\n",
              "0  100002  Nonlinear Shape Statistics in Mumford{Shah Bas...   \n",
              "1  100007                    On the Complexity of Equilibria   \n",
              "2  100008                     On QoS-Aware Publish-Subscribe   \n",
              "3   10001                 Checking Mergeable Priority Queues   \n",
              "4  100012  Mobile Code Security by Java Bytecode Instrume...   \n",
              "\n",
              "                                            abstract  \\\n",
              "0  We present a variational integration of nonlin...   \n",
              "1  We prove complexity, approximability, and inap...   \n",
              "2  This position paper addresses the issue of sup...   \n",
              "3  We present an efficient algorithm which can ch...   \n",
              "4  Mobile code provides significant opportunities...   \n",
              "\n",
              "                                                 bow  \\\n",
              "0  [(0, 1), (1, 1), (3, 1), (4, 1), (5, 1), (6, 1...   \n",
              "1  [(4, 5), (7, 2), (8, 1), (10, 1), (30, 3), (35...   \n",
              "2  [(1, 1), (4, 6), (7, 1), (16, 1), (22, 1), (27...   \n",
              "3  [(4, 7), (7, 2), (8, 1), (10, 1), (16, 1), (17...   \n",
              "4  [(4, 4), (5, 1), (7, 1), (10, 2), (16, 5), (22...   \n",
              "\n",
              "                                              tf_idf  \n",
              "0  [(0, 0.19689725999527163), (1, 0.0861613877917...  \n",
              "1  [(4, 0.0033554011043417254), (7, 0.02333778550...  \n",
              "2  [(1, 0.06276351152911328), (4, 0.0049492930133...  \n",
              "3  [(4, 0.0022699486545179476), (7, 0.01127724975...  \n",
              "4  [(4, 0.001715799318906219), (5, 0.031751265629...  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 67
        }
      ]
    },
    {
      "metadata": {
        "id": "O8F8BfFvTUz8",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Pregunta:** Explicar a qué corresponde la columna `tf_idf` y por qué es útil en el procesamiento de texto. Mencione sus 2 principales partes, mediante la explicación del puntaje.\n",
        "\n",
        "**Respuesta:** Se desea generar una puntuación para obtener la frecuencia de palabras para saber el contexto y poder determinar las palabras dominantes en el texto. Algunas palabras que no son de mucha utilidad van a aparecer con mucha frecuencia, como se quiere evitar eso. Es asi con TF-IDF se busca penalizar palabras que aparecen frecuentemente en un texto como \"the\" u otra palabra que entodos los textos aparecerá pero no da información real sobre el contexto del texto.\n",
        "El proceso entonces entregar puntuación a la fecuencia de las palabras del documento (TF *term frecuency*), y luego generar putuación para las palabras \"raras\" ó poco frecuentes en todos los documentos (IDF *inverse document frecuency*).\n",
        "Es útil en el procesamiento de texto porque se puede ponderar cuando una palabra frecuente es realmente un aporte para conocer el contexto ó es sólo una stopword (artículo, pronombre, etc.).\n"
      ]
    },
    {
      "metadata": {
        "id": "EuNk3cw3SblR",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Generar recomendaciones"
      ]
    },
    {
      "metadata": {
        "id": "vHexXEF-SdH2",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "En esta sección se implementan las funciones necesarias para poder generar recomendaciones dado lo que un usuario ha consumido. De manera artificial, se samplearán 3 documentos aleatorios que representarán al usuario objetivo (`sample`). Luego tendrás que generar diferentes recomendaciones y evaluar los resultados."
      ]
    },
    {
      "metadata": {
        "id": "iwM9JHgpAwwu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 530
        },
        "outputId": "6d709c50-f52a-4475-f7c1-90ec10d70897"
      },
      "cell_type": "code",
      "source": [
        "# Random user\n",
        "\n",
        "samples = corpus_df.sample(3)\n",
        "\n",
        "for n, (ix, paper) in enumerate(samples.iterrows()):\n",
        "  idx, title, abstract, bow, tf_idf = paper\n",
        "  print('%d) %s' % (n+1, title))\n",
        "  print('')\n",
        "  print(abstract)\n",
        "  print('\\n' )"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1) Domino Treewidth\n",
            "\n",
            "We consider a special variant of tree-decompositions, called domino treedecompositions, and the related notion of domino treewidth. In a domino tree-decomposition, each vertex of the graph belongs to at most two nodes of the tree. We prove that for every k, d, there exists a constant c k;d such that a graph with treewidth at most k and maximum degree at most d has domino treewidth at most c k;d . The domino treewidth of a tree can be computed in O(n log n) time. There exist polynomial time algorithms that --- for fixed k --- decide whether a given graph G has domino treewidth at most k. If k is not fixed, this problem is NP-complete. The domino treewidth problem is hard for the complexity classes W [t] for all t 2 N, and hence the problem for fixed k is unlikely to be solvable in O(n ), where c is a constant, not depending on k.\n",
            "\n",
            "\n",
            "2) Truffles - A Secure Service For Widespread File Sharing\n",
            "\n",
            "Truffles is a system meant to address some of the major issues that still make it difficult to share files between users at different sites. In particular, it addresses the problems associated with secure file sharing, and the problems of high administrative overhead. Truffles will combine facilities of the Ficus file system and TIS/PEM, a privacy enhanced mail system, to make file sharing considerably easier. Truffles must deal with several important security problems, including secure transport of data, authentication of the users sharing files, handling of different administrative domains, and permitting system administrators to control, flexibly, yet easily, what sorts of sharing are done. This paper describes these problems and the solutions Truffles will use. INTRODUCTION Users who share a single machine, or who share a single administrative domain over a local area network, are able to share files with each other very easily. Users can share source code for programs they are d...\n",
            "\n",
            "\n",
            "3) Position paper: Motivated Goal and Action Selection\n",
            "\n",
            "A large part of current research into autonomous control is concerned with building agents that can perform useful functions in real-world domains. Consequently, the behaviour of the system must be flexible; the behaviour of an agent must reflect changes in context. This position paper is concerned with the use of motivation as a control mechanism in goal and action selection within an artificial system. It is argued that existing motivated behaviourbased control systems do not effectively give sufficient flexibility; and that a different system based on explicit goal and action representations can more effectively control an autonomous system in a real-world domain. 1 Introduction An autonomous agent, required to act within an environment that can neither be completely nor correctly modelled (i.e., a real-world environment), must have the ability to alter its behaviour as the context within which it is acting changes. Therefore, the ability to create and act to satisfy multiple goals...\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "IarDHEPrAwm_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Recommendation functions\n",
        "\n",
        "N = len(dictionary)\n",
        "\n",
        "def to_sparse(matrix):\n",
        "    return csr_matrix([gensim.matutils.sparse2full(row, length=N) for row in matrix]) \n",
        "\n",
        "def make_recommendations(model, metric, neighbors):\n",
        "    M = len(corpus)\n",
        "\n",
        "    X = to_sparse(corpus_df[model].tolist())\n",
        "    document_index = NearestNeighbors(n_neighbors=(neighbors + 1), algorithm='brute', metric=metric).fit(X)\n",
        "    return document_index\n",
        "\n",
        "def print_recommendations(indexes, model):\n",
        "    for n, (ix, paper) in enumerate(samples.iterrows()):\n",
        "        dists, neighbors = indexes.kneighbors([gensim.matutils.sparse2full(paper[model],length=N)])\n",
        "        print(paper['title'])\n",
        "        print('')\n",
        "        print('Documentos cercanos: ')\n",
        "        i = 1\n",
        "        for neighbour in neighbors[0]:\n",
        "            if ix != neighbour:\n",
        "                line = str(i) + \". \" + corpus_df.iloc[neighbour]['title']\n",
        "                print(line)\n",
        "                i+=1\n",
        "        print('\\n')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dPe8hn3ZTqYO",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "A continuación deberá utilizar las funciones implementadas anteriormente para generar nuevas recomendaciones variando los parámetros del modelo. Agregue nuevas celdas para cada implementación y/o pregunta.\n"
      ]
    },
    {
      "metadata": {
        "id": "EXwYjORwTr17",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "** Pregunta:** Ejecute el modelo utilizando como representación tf-idf y una métrica de distancia euclideana. Modifique el parámetro nearest_neighbors a [5, 10, 20]. ¿qué efecto tiene el modelo en las recomendaciones observadas?\n",
        "\n",
        "**Respuesta:**Las recomendaciones no cambian solo se van incorporando nuevas recomendaciones dependiendo si son 5, 10 ó 20 vecinos cercanos a entregar."
      ]
    },
    {
      "metadata": {
        "id": "CRNEpJy7T6OQ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Pregunta:** Eligiendo un valor fijo para *nearest neighbors* y utilizando representación tf-idf, ejecute el modelo con métrica de distancia *cosine*.¿Qué efecto tiene la métrica de distancia en las recomendaciones observadas?\n",
        "\n",
        "**Respuesta:**La métrica *cosine* no generá ningún cambio en las recomendaciones con respecto a la distancia euclideana, al pedir los 10 vecinos cercanos estos son los mismos para las dos métricas.\n"
      ]
    },
    {
      "metadata": {
        "id": "QfHLV4NrA0-U",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 677
        },
        "outputId": "733b46e3-40a4-46e1-e779-d0b2d269c684"
      },
      "cell_type": "code",
      "source": [
        "# Recommendation example\n",
        " \n",
        "doc_idx = make_recommendations('tf_idf', 'euclidean', 5)\n",
        "print_recommendations(doc_idx, 'tf_idf')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Domino Treewidth\n",
            "\n",
            "Documentos cercanos: \n",
            "1. A Linear Time Algorithm for Finding Tree-Decompositions of Small Treewidth\n",
            "2. Treewidth: Algorithmic techniques and results\n",
            "3. Local Statistics For Random Domino Tilings Of The Aztec Diamond\n",
            "4. A Tutorial on Particle Filters for On-line Nonlinear/Non-Gaussian Bayesian Tracking\n",
            "5. Directed Tree-Width\n",
            "\n",
            "\n",
            "Truffles - A Secure Service For Widespread File Sharing\n",
            "\n",
            "Documentos cercanos: \n",
            "1. Truffles -- Secure File Sharing With Minimal System Administrator Intervention\n",
            "2. Decentralized User Authentication in a Global File System\n",
            "3. Usability and privacy: a study of Kazaa P2P file-sharing\n",
            "4. Alex - a Global Filesystem\n",
            "5. Intra-file Security for a Distributed File System\n",
            "\n",
            "\n",
            "Position paper: Motivated Goal and Action Selection\n",
            "\n",
            "Documentos cercanos: \n",
            "1. Motivation-Based Direction of Planning Attention in Agents With Goal Autonomy\n",
            "2. Anytime Planning For Agent Behaviour\n",
            "3. Induction in Noisy Domains\n",
            "4. Agents and Petri Nets\n",
            "5. Multi-level Control for Animated Autonomous Agents: Do the Right Thing... Oh, Not That...\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "hCuhOpg3eIe6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 999
        },
        "outputId": "2790fc16-fb08-4009-8db8-75efd3681f2e"
      },
      "cell_type": "code",
      "source": [
        "#Recomendacion tf-idf, distancia euclideana, nearest_neighbors 10\n",
        "doc_idx1 = make_recommendations('tf_idf', 'euclidean', 10)\n",
        "print_recommendations(doc_idx1, 'tf_idf')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Domino Treewidth\n",
            "\n",
            "Documentos cercanos: \n",
            "1. A Linear Time Algorithm for Finding Tree-Decompositions of Small Treewidth\n",
            "2. Treewidth: Algorithmic techniques and results\n",
            "3. Local Statistics For Random Domino Tilings Of The Aztec Diamond\n",
            "4. A Tutorial on Particle Filters for On-line Nonlinear/Non-Gaussian Bayesian Tracking\n",
            "5. Directed Tree-Width\n",
            "6. 1.5-Approximation for Treewidth of Graphs Excluding a Graph with One Crossing as a Minor\n",
            "7. The Application of Classical Information Retrieval Techniques to Spoken Documents\n",
            "8. What Cannot Be Computed Locally!\n",
            "9. Constant-Time Distributed Dominating Set Approximation\n",
            "10. Computational Scales Of Sobolev Norms With Application To Preconditioning\n",
            "\n",
            "\n",
            "Truffles - A Secure Service For Widespread File Sharing\n",
            "\n",
            "Documentos cercanos: \n",
            "1. Truffles -- Secure File Sharing With Minimal System Administrator Intervention\n",
            "2. Decentralized User Authentication in a Global File System\n",
            "3. Usability and privacy: a study of Kazaa P2P file-sharing\n",
            "4. Alex - a Global Filesystem\n",
            "5. Intra-file Security for a Distributed File System\n",
            "6. A Caching File System for a Programmer's Workstation\n",
            "7. Make --- A Program for Maintaining Computer Programs\n",
            "8. Semantic File Systems\n",
            "9. Extensible File Systems in Spring\n",
            "10. WebDAVA: An Administrator-Free Approach To Web File-Sharing\n",
            "\n",
            "\n",
            "Position paper: Motivated Goal and Action Selection\n",
            "\n",
            "Documentos cercanos: \n",
            "1. Motivation-Based Direction of Planning Attention in Agents With Goal Autonomy\n",
            "2. Anytime Planning For Agent Behaviour\n",
            "3. Induction in Noisy Domains\n",
            "4. Agents and Petri Nets\n",
            "5. Multi-level Control for Animated Autonomous Agents: Do the Right Thing... Oh, Not That...\n",
            "6. Combining Symbolic and Neural Learning to Revise Probabilistic Theories\n",
            "7. Parallel Adaptive Tabu Search for Large Optimization Problems\n",
            "8. Computer Vision-Based Registration Techniques for Augmented Reality\n",
            "9. Emergent Coordination through the Use of Cooperative State-Changing Rules\n",
            "10. Optimal Brain Damage\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "LxF_s__VeIq5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1251
        },
        "outputId": "d5459612-95c4-4787-bf6e-d0278cdd7aaa"
      },
      "cell_type": "code",
      "source": [
        "#Recomendacion tf-idf, distancia euclideana, nearest_neighbors 20\n",
        "doc_idx2 = make_recommendations('tf_idf', 'euclidean', 20)\n",
        "print_recommendations(doc_idx2, 'tf_idf')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Domino Treewidth\n",
            "\n",
            "Documentos cercanos: \n",
            "1. A Linear Time Algorithm for Finding Tree-Decompositions of Small Treewidth\n",
            "2. Treewidth: Algorithmic techniques and results\n",
            "3. Local Statistics For Random Domino Tilings Of The Aztec Diamond\n",
            "4. A Tutorial on Particle Filters for On-line Nonlinear/Non-Gaussian Bayesian Tracking\n",
            "5. Directed Tree-Width\n",
            "6. 1.5-Approximation for Treewidth of Graphs Excluding a Graph with One Crossing as a Minor\n",
            "7. The Application of Classical Information Retrieval Techniques to Spoken Documents\n",
            "8. What Cannot Be Computed Locally!\n",
            "9. Constant-Time Distributed Dominating Set Approximation\n",
            "10. Computational Scales Of Sobolev Norms With Application To Preconditioning\n",
            "11. Broadcast Encryption\n",
            "12. On Geometric Optimization With Few Violated Constraints\n",
            "13. Fixed-Parameter Tractability and Completeness I: Basic Results\n",
            "14. Characteristic Varieties Of Arrangements\n",
            "15. The Discrete Cosine Transform\n",
            "16. The Union Of Convex Polyhedra In Three Dimensions\n",
            "17. Arboricity and Bipartite Subgraph Listing Algorithms\n",
            "18. An Efficient Approximation Algorithm for the Survivable Network Design Problem\n",
            "19. Fast Ray Tracing Using K-D Trees\n",
            "20. On the Complexity of the Union of Fat Objects in the Plane\n",
            "\n",
            "\n",
            "Truffles - A Secure Service For Widespread File Sharing\n",
            "\n",
            "Documentos cercanos: \n",
            "1. Truffles -- Secure File Sharing With Minimal System Administrator Intervention\n",
            "2. Decentralized User Authentication in a Global File System\n",
            "3. Usability and privacy: a study of Kazaa P2P file-sharing\n",
            "4. Alex - a Global Filesystem\n",
            "5. Intra-file Security for a Distributed File System\n",
            "6. A Caching File System for a Programmer's Workstation\n",
            "7. Make --- A Program for Maintaining Computer Programs\n",
            "8. Semantic File Systems\n",
            "9. Extensible File Systems in Spring\n",
            "10. WebDAVA: An Administrator-Free Approach To Web File-Sharing\n",
            "11. An Analytical Approach to File Prefetching\n",
            "12. Experience Building a File System on a Highly Modular Operating System\n",
            "13. A Text Compression Scheme That Allows Fast Searching Directly In The Compressed File\n",
            "14. Eager Sharing for Efficient Massive Parallelism\n",
            "15. Small-World File-Sharing Communities\n",
            "16. Dynamic Sharing and Backward Compatibility on 64-Bit Machines\n",
            "17. Query Processing over Peer-to-Peer Data Sharing Systems\n",
            "18. Taming aggressive replication in the Pangaea wide-area file system\n",
            "19. The Vesta Repository: A File System Extension for Software Development\n",
            "20. An Experiment to Characterize Videos Stored On The Web\n",
            "\n",
            "\n",
            "Position paper: Motivated Goal and Action Selection\n",
            "\n",
            "Documentos cercanos: \n",
            "1. Motivation-Based Direction of Planning Attention in Agents With Goal Autonomy\n",
            "2. Anytime Planning For Agent Behaviour\n",
            "3. Induction in Noisy Domains\n",
            "4. Agents and Petri Nets\n",
            "5. Multi-level Control for Animated Autonomous Agents: Do the Right Thing... Oh, Not That...\n",
            "6. Combining Symbolic and Neural Learning to Revise Probabilistic Theories\n",
            "7. Parallel Adaptive Tabu Search for Large Optimization Problems\n",
            "8. Computer Vision-Based Registration Techniques for Augmented Reality\n",
            "9. Emergent Coordination through the Use of Cooperative State-Changing Rules\n",
            "10. Optimal Brain Damage\n",
            "11. Learning Probabilistic Models of Relational Structure\n",
            "12. On the Applicability of Schema Integration Techniques to Database Interoperation\n",
            "13. A Case Study in the Behavior-Oriented Design of Autonomous Agents.\n",
            "14. Multidimensional Data Modeling for Complex Data\n",
            "15. Integrating Active Concepts into an Object-Oriented Database System\n",
            "16. SIM AGENT: A toolkit for exploring agent designs\n",
            "17. How To Evolve Autonomous Robots: Different Approaches In Evolutionary Robotics\n",
            "18. Learning Despite Concept Variation by Finding Structure in Attribute-based Data\n",
            "19. Representing and Executing Agent-Based Systems\n",
            "20. Formalising Motivational Attitudes of Agents Using the KARO Framework\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "olVsAwbZeI7k",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 999
        },
        "outputId": "e8a2d47f-1043-4b90-f5a4-eb0aaaf30885"
      },
      "cell_type": "code",
      "source": [
        "#Recomendacion tf-idf, distancia cosine, nearest_neighbors 10\n",
        "doc_idx1 = make_recommendations('tf_idf', 'cosine', 10)\n",
        "print_recommendations(doc_idx1, 'tf_idf')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Domino Treewidth\n",
            "\n",
            "Documentos cercanos: \n",
            "1. A Linear Time Algorithm for Finding Tree-Decompositions of Small Treewidth\n",
            "2. Treewidth: Algorithmic techniques and results\n",
            "3. Local Statistics For Random Domino Tilings Of The Aztec Diamond\n",
            "4. A Tutorial on Particle Filters for On-line Nonlinear/Non-Gaussian Bayesian Tracking\n",
            "5. Directed Tree-Width\n",
            "6. 1.5-Approximation for Treewidth of Graphs Excluding a Graph with One Crossing as a Minor\n",
            "7. The Application of Classical Information Retrieval Techniques to Spoken Documents\n",
            "8. What Cannot Be Computed Locally!\n",
            "9. Constant-Time Distributed Dominating Set Approximation\n",
            "10. Computational Scales Of Sobolev Norms With Application To Preconditioning\n",
            "\n",
            "\n",
            "Truffles - A Secure Service For Widespread File Sharing\n",
            "\n",
            "Documentos cercanos: \n",
            "1. Truffles -- Secure File Sharing With Minimal System Administrator Intervention\n",
            "2. Decentralized User Authentication in a Global File System\n",
            "3. Usability and privacy: a study of Kazaa P2P file-sharing\n",
            "4. Alex - a Global Filesystem\n",
            "5. Intra-file Security for a Distributed File System\n",
            "6. A Caching File System for a Programmer's Workstation\n",
            "7. Make --- A Program for Maintaining Computer Programs\n",
            "8. Semantic File Systems\n",
            "9. Extensible File Systems in Spring\n",
            "10. WebDAVA: An Administrator-Free Approach To Web File-Sharing\n",
            "\n",
            "\n",
            "Position paper: Motivated Goal and Action Selection\n",
            "\n",
            "Documentos cercanos: \n",
            "1. Motivation-Based Direction of Planning Attention in Agents With Goal Autonomy\n",
            "2. Anytime Planning For Agent Behaviour\n",
            "3. Induction in Noisy Domains\n",
            "4. Agents and Petri Nets\n",
            "5. Multi-level Control for Animated Autonomous Agents: Do the Right Thing... Oh, Not That...\n",
            "6. Combining Symbolic and Neural Learning to Revise Probabilistic Theories\n",
            "7. Parallel Adaptive Tabu Search for Large Optimization Problems\n",
            "8. Computer Vision-Based Registration Techniques for Augmented Reality\n",
            "9. Emergent Coordination through the Use of Cooperative State-Changing Rules\n",
            "10. Optimal Brain Damage\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}